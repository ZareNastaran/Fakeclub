{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647dc794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be67474",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews = pd.read_csv(\"C:\\\\Users\\\\TRSM\\\\Downloads\\\\Telegram Desktop\\\\Review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c09e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-08</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358952</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>I'm very spoiled with Pizza. Really, I have tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358953</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>Can't say enough good things about this place....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358954</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>Had a great dinner here- fantastic pizza, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358955</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>Great foods and great drinks, they have even p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358956</th>\n",
       "      <td>5260</td>\n",
       "      <td>349</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>Pizza Loves Emily and I love Emily's pizza. Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358957 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Product ID        Date  \\\n",
       "0           923           0  2014-12-08   \n",
       "1           924           0  2013-05-16   \n",
       "2           925           0  2013-07-01   \n",
       "3           926           0  2011-07-28   \n",
       "4           927           0  2010-11-01   \n",
       "...         ...         ...         ...   \n",
       "358952   161146         349  2014-02-06   \n",
       "358953   116424         349  2014-01-31   \n",
       "358954   161147         349  2014-01-30   \n",
       "358955    97930         349  2014-01-25   \n",
       "358956     5260         349  2014-01-25   \n",
       "\n",
       "                                                   Review  Rating  Label  \n",
       "0       The food at snack is a selection of popular Gr...       3     -1  \n",
       "1       This little place in Soho is wonderful. I had ...       3     -1  \n",
       "2       ordered lunch for 15 from Snack last Friday.  ...       4     -1  \n",
       "3       This is a beautiful quaint little restaurant o...       4     -1  \n",
       "4       Snack is great place for a  casual sit down lu...       4     -1  \n",
       "...                                                   ...     ...    ...  \n",
       "358952  I'm very spoiled with Pizza. Really, I have tr...       2      1  \n",
       "358953  Can't say enough good things about this place....       5      1  \n",
       "358954  Had a great dinner here- fantastic pizza, the ...       2      1  \n",
       "358955  Great foods and great drinks, they have even p...       5      1  \n",
       "358956  Pizza Loves Emily and I love Emily's pizza. Th...       5      1  \n",
       "\n",
       "[358957 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7fed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = Reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caadb7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID       0\n",
       "Product ID    0\n",
       "Date          0\n",
       "Review        0\n",
       "Rating        0\n",
       "Label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9b13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews['Date'] = pd.to_datetime(Reviews['Date'])\n",
    "# Replace the date column with numerical value\n",
    "Reviews['Date'] = (Reviews['Date'] - Reviews['Date'].min()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd254350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3130</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>3176</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>2472</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>2203</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358952</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>3396</td>\n",
       "      <td>I'm very spoiled with Pizza. Really, I have tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358953</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>3390</td>\n",
       "      <td>Can't say enough good things about this place....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358954</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>3389</td>\n",
       "      <td>Had a great dinner here- fantastic pizza, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358955</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Great foods and great drinks, they have even p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358956</th>\n",
       "      <td>5260</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Pizza Loves Emily and I love Emily's pizza. Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358957 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Product ID  Date  \\\n",
       "0           923           0  3701   \n",
       "1           924           0  3130   \n",
       "2           925           0  3176   \n",
       "3           926           0  2472   \n",
       "4           927           0  2203   \n",
       "...         ...         ...   ...   \n",
       "358952   161146         349  3396   \n",
       "358953   116424         349  3390   \n",
       "358954   161147         349  3389   \n",
       "358955    97930         349  3384   \n",
       "358956     5260         349  3384   \n",
       "\n",
       "                                                   Review  Rating  Label  \n",
       "0       The food at snack is a selection of popular Gr...       3     -1  \n",
       "1       This little place in Soho is wonderful. I had ...       3     -1  \n",
       "2       ordered lunch for 15 from Snack last Friday.  ...       4     -1  \n",
       "3       This is a beautiful quaint little restaurant o...       4     -1  \n",
       "4       Snack is great place for a  casual sit down lu...       4     -1  \n",
       "...                                                   ...     ...    ...  \n",
       "358952  I'm very spoiled with Pizza. Really, I have tr...       2      1  \n",
       "358953  Can't say enough good things about this place....       5      1  \n",
       "358954  Had a great dinner here- fantastic pizza, the ...       2      1  \n",
       "358955  Great foods and great drinks, they have even p...       5      1  \n",
       "358956  Pizza Loves Emily and I love Emily's pizza. Th...       5      1  \n",
       "\n",
       "[358957 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487d0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding product IDs with many real or fake reveiws as outlier to remove them\n",
    "review_counts = Reviews.groupby(['Product ID', 'Label']).size().unstack(fill_value=0)\n",
    "review_counts = review_counts.reset_index()\n",
    "review_counts.columns.name = None\n",
    "review_counts.rename(columns={'fake': 'Fake Reviews', 'genuine': 'Genuine Reviews'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e7810b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>21</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>919</td>\n",
       "      <td>82</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>920</td>\n",
       "      <td>28</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>921</td>\n",
       "      <td>33</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>922</td>\n",
       "      <td>40</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product ID  -1    1\n",
       "0             0  14  196\n",
       "1             1  42  211\n",
       "2             2  19  147\n",
       "3             3   9   50\n",
       "4             4  37  510\n",
       "..          ...  ..  ...\n",
       "918         918  21  368\n",
       "919         919  82  404\n",
       "920         920  28  278\n",
       "921         921  33  159\n",
       "922         922  40  784\n",
       "\n",
       "[923 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef6cd10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in the 'Fake Reviews' column:\n",
      "     Product ID   -1     1  Fake Z-score  Real Z-score\n",
      "78           78  249  1431      3.200045      2.122329\n",
      "120         120  411  1562      5.680013      2.379270\n",
      "211         211  271  2577      3.536831      4.370069\n",
      "247         247  704  6674     10.165387     12.405839\n",
      "363         363  316  1749      4.225711      2.746047\n",
      "416         416  353  1830      4.792123      2.904919\n",
      "454         454  249  1909      3.200045      3.059868\n",
      "465         465  544  3391      7.716036      5.966632\n",
      "484         484  247  1685      3.169428      2.620519\n",
      "521         521  409  1663      5.649396      2.577369\n",
      "542         542  701  4015     10.119462      7.190532\n",
      "555         555  797  5835     11.589072     10.760242\n",
      "658         658  444  1721      6.185192      2.691129\n",
      "668         668  362  2581      4.929899      4.377915\n",
      "\n",
      "Outliers in the 'Real Reviews' column:\n",
      "     Product ID   -1     1  Fake Z-score  Real Z-score\n",
      "72           72  194  2805      2.358081      4.817263\n",
      "91           91  181  2941      2.159071      5.084011\n",
      "100         100  181  2496      2.159071      4.211197\n",
      "211         211  271  2577      3.536831      4.370069\n",
      "247         247  704  6674     10.165387     12.405839\n",
      "414         414  194  2098      2.358081      3.430569\n",
      "454         454  249  1909      3.200045      3.059868\n",
      "465         465  544  3391      7.716036      5.966632\n",
      "468         468  226  2917      2.847951      5.036938\n",
      "510         510  200  2360      2.449931      3.944450\n",
      "542         542  701  4015     10.119462      7.190532\n",
      "555         555  797  5835     11.589072     10.760242\n",
      "604         604  183  2353      2.189688      3.930720\n",
      "668         668  362  2581      4.929899      4.377915\n"
     ]
    }
   ],
   "source": [
    "#now by Z-score statistical method I want to specify the product ID outliers\n",
    "from scipy import stats\n",
    "review_counts['Fake Z-score'] = np.abs(stats.zscore(review_counts[-1]))\n",
    "review_counts['Real Z-score'] = np.abs(stats.zscore(review_counts[1]))\n",
    "z_threshold = 3\n",
    "fake_outliers = review_counts[review_counts['Fake Z-score'] > z_threshold]\n",
    "real_outliers = review_counts[review_counts['Real Z-score'] > z_threshold]\n",
    "print(\"Outliers in the 'Fake Reviews' column:\")\n",
    "print(fake_outliers)\n",
    "\n",
    "print(\"\\nOutliers in the 'Real Reviews' column:\")\n",
    "print(real_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae24edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_product_ids = list(set(fake_outliers['Product ID']).union(set(real_outliers['Product ID'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286aef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[454,\n",
       " 72,\n",
       " 521,\n",
       " 78,\n",
       " 465,\n",
       " 658,\n",
       " 211,\n",
       " 468,\n",
       " 91,\n",
       " 668,\n",
       " 604,\n",
       " 542,\n",
       " 414,\n",
       " 416,\n",
       " 484,\n",
       " 100,\n",
       " 363,\n",
       " 555,\n",
       " 247,\n",
       " 120,\n",
       " 510]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdec6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reviews = Reviews[~Reviews['Product ID'].isin(outlier_product_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5441aa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3130</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>3176</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>2472</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>2203</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358952</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>3396</td>\n",
       "      <td>I'm very spoiled with Pizza. Really, I have tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358953</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>3390</td>\n",
       "      <td>Can't say enough good things about this place....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358954</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>3389</td>\n",
       "      <td>Had a great dinner here- fantastic pizza, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358955</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Great foods and great drinks, they have even p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358956</th>\n",
       "      <td>5260</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Pizza Loves Emily and I love Emily's pizza. Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294948 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Product ID  Date  \\\n",
       "0           923           0  3701   \n",
       "1           924           0  3130   \n",
       "2           925           0  3176   \n",
       "3           926           0  2472   \n",
       "4           927           0  2203   \n",
       "...         ...         ...   ...   \n",
       "358952   161146         349  3396   \n",
       "358953   116424         349  3390   \n",
       "358954   161147         349  3389   \n",
       "358955    97930         349  3384   \n",
       "358956     5260         349  3384   \n",
       "\n",
       "                                                   Review  Rating  Label  \n",
       "0       The food at snack is a selection of popular Gr...       3     -1  \n",
       "1       This little place in Soho is wonderful. I had ...       3     -1  \n",
       "2       ordered lunch for 15 from Snack last Friday.  ...       4     -1  \n",
       "3       This is a beautiful quaint little restaurant o...       4     -1  \n",
       "4       Snack is great place for a  casual sit down lu...       4     -1  \n",
       "...                                                   ...     ...    ...  \n",
       "358952  I'm very spoiled with Pizza. Really, I have tr...       2      1  \n",
       "358953  Can't say enough good things about this place....       5      1  \n",
       "358954  Had a great dinner here- fantastic pizza, the ...       2      1  \n",
       "358955  Great foods and great drinks, they have even p...       5      1  \n",
       "358956  Pizza Loves Emily and I love Emily's pizza. Th...       5      1  \n",
       "\n",
       "[294948 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c045ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now seeing the User ID distribution\n",
    "user_review_counts = Reviews.groupby(['User ID', 'Label']).size().unstack(fill_value=0)\n",
    "user_review_counts = user_review_counts.reset_index()\n",
    "user_review_counts.columns.name = None\n",
    "user_review_counts.rename(columns={-1: 'Fake Reviews', 1: 'Genuine Reviews'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4fcc67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Fake Reviews</th>\n",
       "      <th>Genuine Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160196</th>\n",
       "      <td>161143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160197</th>\n",
       "      <td>161144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160198</th>\n",
       "      <td>161145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160199</th>\n",
       "      <td>161146</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160200</th>\n",
       "      <td>161147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Fake Reviews  Genuine Reviews\n",
       "0           923            13               26\n",
       "1           924             1                0\n",
       "2           925             2                0\n",
       "3           926             1                0\n",
       "4           927             2                3\n",
       "...         ...           ...              ...\n",
       "160196   161143             0                1\n",
       "160197   161144             0                1\n",
       "160198   161145             0                1\n",
       "160199   161146             0                1\n",
       "160200   161147             0                1\n",
       "\n",
       "[160201 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_review_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a612ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in the 'Fake Reviews' column:\n",
      "        User ID  Fake Reviews  Genuine Reviews  Fake Z-score  Real Z-score\n",
      "0           923            13               26     21.170867      6.081412\n",
      "8           931            20               11     32.776105      2.278878\n",
      "39          962             6               67      9.565630     16.475006\n",
      "40          963             3               35      4.591957      8.362933\n",
      "43          966             3               60      4.591957     14.700490\n",
      "...         ...           ...              ...           ...           ...\n",
      "120777   121723             3                0      4.591957      0.509647\n",
      "120967   121913             3                0      4.591957      0.509647\n",
      "122045   122991             3                3      4.591957      0.250860\n",
      "124648   125594             3                0      4.591957      0.509647\n",
      "135670   136617             3                3      4.591957      0.250860\n",
      "\n",
      "[1404 rows x 5 columns]\n",
      "\n",
      "Outliers in the 'Real Reviews' column:\n",
      "       User ID  Fake Reviews  Genuine Reviews  Fake Z-score  Real Z-score\n",
      "0          923            13               26     21.170867      6.081412\n",
      "36         959             1               38      1.276175      9.123440\n",
      "37         960             1               28      1.276175      6.588417\n",
      "39         962             6               67      9.565630     16.475006\n",
      "40         963             3               35      4.591957      8.362933\n",
      "...        ...           ...              ...           ...           ...\n",
      "59604    60542             0               14      0.381716      3.039385\n",
      "59776    60714             1               17      1.276175      3.799892\n",
      "59968    60906             1               14      1.276175      3.039385\n",
      "62592    63530             0               14      0.381716      3.039385\n",
      "68216    69154             0               17      0.381716      3.799892\n",
      "\n",
      "[2595 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#now by Z-score statistical method I want to specify the User ID outliers however I didn't run this for the last version\n",
    "from scipy import stats\n",
    "user_review_counts['Fake Z-score'] = np.abs(stats.zscore(user_review_counts[\"Fake Reviews\"]))\n",
    "user_review_counts['Real Z-score'] = np.abs(stats.zscore(user_review_counts[\"Genuine Reviews\"]))\n",
    "z_threshold = 3\n",
    "fake_user_outliers = user_review_counts[user_review_counts['Fake Z-score'] > z_threshold]\n",
    "real_user_outliers = user_review_counts[user_review_counts['Real Z-score'] > z_threshold]\n",
    "print(\"Outliers in the 'Fake Reviews' column:\")\n",
    "print(fake_user_outliers)\n",
    "\n",
    "print(\"\\nOutliers in the 'Real Reviews' column:\")\n",
    "print(real_user_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84df075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_user_ids = list(set(fake_user_outliers['User ID']).union(set(real_user_outliers['User ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "516c9418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16385,\n",
       " 8196,\n",
       " 8200,\n",
       " 8201,\n",
       " 8203,\n",
       " 8206,\n",
       " 8207,\n",
       " 16407,\n",
       " 16421,\n",
       " 8229,\n",
       " 8232,\n",
       " 16428,\n",
       " 8240,\n",
       " 16433,\n",
       " 32821,\n",
       " 16438,\n",
       " 8251,\n",
       " 8257,\n",
       " 32838,\n",
       " 24651,\n",
       " 57420,\n",
       " 49233,\n",
       " 8274,\n",
       " 8275,\n",
       " 24662,\n",
       " 8279,\n",
       " 8280,\n",
       " 8281,\n",
       " 32855,\n",
       " 8284,\n",
       " 57437,\n",
       " 41054,\n",
       " 8289,\n",
       " 49254,\n",
       " 8296,\n",
       " 57449,\n",
       " 122991,\n",
       " 8305,\n",
       " 32886,\n",
       " 16504,\n",
       " 32890,\n",
       " 8320,\n",
       " 16513,\n",
       " 49281,\n",
       " 8325,\n",
       " 8326,\n",
       " 16519,\n",
       " 24715,\n",
       " 8332,\n",
       " 8336,\n",
       " 8337,\n",
       " 8339,\n",
       " 8352,\n",
       " 16545,\n",
       " 8355,\n",
       " 24740,\n",
       " 16551,\n",
       " 16552,\n",
       " 8359,\n",
       " 57514,\n",
       " 8361,\n",
       " 41133,\n",
       " 8366,\n",
       " 24754,\n",
       " 16563,\n",
       " 16570,\n",
       " 24769,\n",
       " 16578,\n",
       " 8387,\n",
       " 8388,\n",
       " 24771,\n",
       " 24773,\n",
       " 8397,\n",
       " 57575,\n",
       " 8436,\n",
       " 8440,\n",
       " 8442,\n",
       " 16635,\n",
       " 16636,\n",
       " 16637,\n",
       " 16642,\n",
       " 8454,\n",
       " 8455,\n",
       " 16650,\n",
       " 16652,\n",
       " 24845,\n",
       " 8460,\n",
       " 24847,\n",
       " 8472,\n",
       " 8476,\n",
       " 74013,\n",
       " 16672,\n",
       " 74028,\n",
       " 82237,\n",
       " 49469,\n",
       " 24908,\n",
       " 41299,\n",
       " 8535,\n",
       " 8536,\n",
       " 33115,\n",
       " 8542,\n",
       " 8543,\n",
       " 16738,\n",
       " 16740,\n",
       " 74086,\n",
       " 33127,\n",
       " 8553,\n",
       " 8554,\n",
       " 8558,\n",
       " 16750,\n",
       " 49520,\n",
       " 8560,\n",
       " 33135,\n",
       " 8571,\n",
       " 16764,\n",
       " 33152,\n",
       " 49547,\n",
       " 24972,\n",
       " 8593,\n",
       " 16793,\n",
       " 16800,\n",
       " 25001,\n",
       " 8621,\n",
       " 16816,\n",
       " 82357,\n",
       " 16825,\n",
       " 8634,\n",
       " 8636,\n",
       " 8638,\n",
       " 33223,\n",
       " 16840,\n",
       " 8657,\n",
       " 8658,\n",
       " 33234,\n",
       " 8660,\n",
       " 16853,\n",
       " 25053,\n",
       " 8671,\n",
       " 16866,\n",
       " 8679,\n",
       " 8680,\n",
       " 16871,\n",
       " 16873,\n",
       " 8683,\n",
       " 25063,\n",
       " 16877,\n",
       " 25065,\n",
       " 25070,\n",
       " 8688,\n",
       " 33260,\n",
       " 16889,\n",
       " 33275,\n",
       " 16892,\n",
       " 16895,\n",
       " 16896,\n",
       " 8709,\n",
       " 8712,\n",
       " 16905,\n",
       " 33288,\n",
       " 8718,\n",
       " 8721,\n",
       " 16919,\n",
       " 25114,\n",
       " 16923,\n",
       " 8738,\n",
       " 25127,\n",
       " 8748,\n",
       " 16943,\n",
       " 16952,\n",
       " 33336,\n",
       " 8773,\n",
       " 16965,\n",
       " 49738,\n",
       " 33357,\n",
       " 57938,\n",
       " 16979,\n",
       " 8789,\n",
       " 33369,\n",
       " 8794,\n",
       " 16987,\n",
       " 8797,\n",
       " 33375,\n",
       " 57957,\n",
       " 57962,\n",
       " 8814,\n",
       " 49777,\n",
       " 90739,\n",
       " 25207,\n",
       " 57977,\n",
       " 57978,\n",
       " 57979,\n",
       " 17021,\n",
       " 8833,\n",
       " 25221,\n",
       " 8839,\n",
       " 25229,\n",
       " 25234,\n",
       " 8853,\n",
       " 58006,\n",
       " 8857,\n",
       " 17056,\n",
       " 25249,\n",
       " 8865,\n",
       " 25251,\n",
       " 8871,\n",
       " 25274,\n",
       " 17082,\n",
       " 17090,\n",
       " 8899,\n",
       " 25284,\n",
       " 41679,\n",
       " 17105,\n",
       " 8923,\n",
       " 74463,\n",
       " 8928,\n",
       " 25314,\n",
       " 8931,\n",
       " 41701,\n",
       " 25320,\n",
       " 8937,\n",
       " 33515,\n",
       " 17141,\n",
       " 17149,\n",
       " 8958,\n",
       " 49918,\n",
       " 8962,\n",
       " 8963,\n",
       " 8964,\n",
       " 8965,\n",
       " 17161,\n",
       " 25356,\n",
       " 8980,\n",
       " 99092,\n",
       " 33558,\n",
       " 41751,\n",
       " 8986,\n",
       " 33565,\n",
       " 8991,\n",
       " 8993,\n",
       " 25377,\n",
       " 8995,\n",
       " 8996,\n",
       " 17186,\n",
       " 107302,\n",
       " 8997,\n",
       " 17195,\n",
       " 25388,\n",
       " 9003,\n",
       " 33580,\n",
       " 25392,\n",
       " 66352,\n",
       " 9008,\n",
       " 9014,\n",
       " 9018,\n",
       " 9019,\n",
       " 9033,\n",
       " 9039,\n",
       " 9046,\n",
       " 25430,\n",
       " 9050,\n",
       " 9052,\n",
       " 9055,\n",
       " 9056,\n",
       " 9057,\n",
       " 17250,\n",
       " 17252,\n",
       " 33637,\n",
       " 9064,\n",
       " 25449,\n",
       " 107370,\n",
       " 17261,\n",
       " 9072,\n",
       " 9075,\n",
       " 9077,\n",
       " 25464,\n",
       " 25469,\n",
       " 9087,\n",
       " 9088,\n",
       " 17280,\n",
       " 9092,\n",
       " 17285,\n",
       " 9101,\n",
       " 9110,\n",
       " 923,\n",
       " 107419,\n",
       " 9119,\n",
       " 17314,\n",
       " 931,\n",
       " 25508,\n",
       " 25509,\n",
       " 41891,\n",
       " 82851,\n",
       " 9124,\n",
       " 9126,\n",
       " 41899,\n",
       " 33708,\n",
       " 17337,\n",
       " 107451,\n",
       " 959,\n",
       " 960,\n",
       " 17345,\n",
       " 962,\n",
       " 963,\n",
       " 107460,\n",
       " 17348,\n",
       " 966,\n",
       " 33737,\n",
       " 969,\n",
       " 17355,\n",
       " 976,\n",
       " 9172,\n",
       " 983,\n",
       " 17368,\n",
       " 9177,\n",
       " 9183,\n",
       " 992,\n",
       " 9185,\n",
       " 33762,\n",
       " 9191,\n",
       " 999,\n",
       " 9193,\n",
       " 17384,\n",
       " 1003,\n",
       " 9196,\n",
       " 1004,\n",
       " 9201,\n",
       " 1010,\n",
       " 1011,\n",
       " 17394,\n",
       " 1014,\n",
       " 1015,\n",
       " 41976,\n",
       " 1023,\n",
       " 9215,\n",
       " 9219,\n",
       " 1029,\n",
       " 1031,\n",
       " 9224,\n",
       " 25611,\n",
       " 107537,\n",
       " 1041,\n",
       " 9236,\n",
       " 17430,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1050,\n",
       " 1053,\n",
       " 66589,\n",
       " 9247,\n",
       " 9248,\n",
       " 17438,\n",
       " 25632,\n",
       " 1059,\n",
       " 1060,\n",
       " 17443,\n",
       " 9254,\n",
       " 17447,\n",
       " 17449,\n",
       " 107564,\n",
       " 17455,\n",
       " 33839,\n",
       " 9265,\n",
       " 17457,\n",
       " 42033,\n",
       " 1078,\n",
       " 1079,\n",
       " 25656,\n",
       " 1081,\n",
       " 9275,\n",
       " 9276,\n",
       " 9277,\n",
       " 1085,\n",
       " 1088,\n",
       " 17472,\n",
       " 25667,\n",
       " 1093,\n",
       " 1094,\n",
       " 17482,\n",
       " 1100,\n",
       " 1101,\n",
       " 1109,\n",
       " 9302,\n",
       " 9304,\n",
       " 17496,\n",
       " 9310,\n",
       " 1118,\n",
       " 1120,\n",
       " 1121,\n",
       " 1123,\n",
       " 1128,\n",
       " 25705,\n",
       " 1129,\n",
       " 17512,\n",
       " 17516,\n",
       " 1131,\n",
       " 1132,\n",
       " 9327,\n",
       " 9326,\n",
       " 107634,\n",
       " 17524,\n",
       " 1141,\n",
       " 1143,\n",
       " 9338,\n",
       " 33916,\n",
       " 17533,\n",
       " 25726,\n",
       " 1153,\n",
       " 17539,\n",
       " 17542,\n",
       " 9351,\n",
       " 9352,\n",
       " 17543,\n",
       " 1166,\n",
       " 74896,\n",
       " 83088,\n",
       " 17555,\n",
       " 107668,\n",
       " 17558,\n",
       " 9373,\n",
       " 9375,\n",
       " 17570,\n",
       " 9380,\n",
       " 17573,\n",
       " 25765,\n",
       " 1191,\n",
       " 1192,\n",
       " 17581,\n",
       " 9392,\n",
       " 1200,\n",
       " 17586,\n",
       " 42163,\n",
       " 1204,\n",
       " 1205,\n",
       " 1206,\n",
       " 9399,\n",
       " 17592,\n",
       " 1210,\n",
       " 9407,\n",
       " 17602,\n",
       " 9411,\n",
       " 9412,\n",
       " 1222,\n",
       " 9416,\n",
       " 17608,\n",
       " 9418,\n",
       " 1226,\n",
       " 1230,\n",
       " 50382,\n",
       " 107726,\n",
       " 1234,\n",
       " 25812,\n",
       " 1239,\n",
       " 1240,\n",
       " 1241,\n",
       " 17624,\n",
       " 17625,\n",
       " 25817,\n",
       " 9437,\n",
       " 1246,\n",
       " 17633,\n",
       " 17640,\n",
       " 1258,\n",
       " 17646,\n",
       " 25838,\n",
       " 9457,\n",
       " 17650,\n",
       " 34034,\n",
       " 1270,\n",
       " 25847,\n",
       " 1275,\n",
       " 1278,\n",
       " 42239,\n",
       " 17665,\n",
       " 1283,\n",
       " 17668,\n",
       " 1285,\n",
       " 1286,\n",
       " 1287,\n",
       " 25859,\n",
       " 1289,\n",
       " 9483,\n",
       " 17676,\n",
       " 1294,\n",
       " 9487,\n",
       " 1296,\n",
       " 34063,\n",
       " 1301,\n",
       " 1302,\n",
       " 1306,\n",
       " 9501,\n",
       " 34077,\n",
       " 42271,\n",
       " 9505,\n",
       " 17705,\n",
       " 17706,\n",
       " 75054,\n",
       " 9520,\n",
       " 9521,\n",
       " 9522,\n",
       " 1332,\n",
       " 34101,\n",
       " 9526,\n",
       " 9524,\n",
       " 1334,\n",
       " 17717,\n",
       " 17718,\n",
       " 1339,\n",
       " 1340,\n",
       " 50494,\n",
       " 1345,\n",
       " 1348,\n",
       " 1349,\n",
       " 1355,\n",
       " 58700,\n",
       " 25932,\n",
       " 1361,\n",
       " 34141,\n",
       " 1373,\n",
       " 1374,\n",
       " 1378,\n",
       " 1381,\n",
       " 1382,\n",
       " 34151,\n",
       " 1384,\n",
       " 17775,\n",
       " 9583,\n",
       " 9584,\n",
       " 17778,\n",
       " 25976,\n",
       " 34170,\n",
       " 42367,\n",
       " 9601,\n",
       " 17800,\n",
       " 9608,\n",
       " 34185,\n",
       " 9614,\n",
       " 1423,\n",
       " 26006,\n",
       " 9623,\n",
       " 26012,\n",
       " 17822,\n",
       " 17825,\n",
       " 17831,\n",
       " 9640,\n",
       " 9639,\n",
       " 9642,\n",
       " 1451,\n",
       " 1455,\n",
       " 42417,\n",
       " 9655,\n",
       " 17852,\n",
       " 9661,\n",
       " 17854,\n",
       " 9670,\n",
       " 83399,\n",
       " 26057,\n",
       " 9677,\n",
       " 26061,\n",
       " 26062,\n",
       " 1491,\n",
       " 42452,\n",
       " 1493,\n",
       " 26070,\n",
       " 17880,\n",
       " 17881,\n",
       " 1496,\n",
       " 9689,\n",
       " 42460,\n",
       " 26078,\n",
       " 9696,\n",
       " 9698,\n",
       " 26088,\n",
       " 17897,\n",
       " 1514,\n",
       " 42473,\n",
       " 1516,\n",
       " 17900,\n",
       " 1519,\n",
       " 9713,\n",
       " 1522,\n",
       " 1524,\n",
       " 34293,\n",
       " 83446,\n",
       " 1525,\n",
       " 9722,\n",
       " 91645,\n",
       " 42493,\n",
       " 9727,\n",
       " 1536,\n",
       " 17924,\n",
       " 17927,\n",
       " 1545,\n",
       " 50699,\n",
       " 9740,\n",
       " 1549,\n",
       " 17934,\n",
       " 17935,\n",
       " 42515,\n",
       " 1555,\n",
       " 9747,\n",
       " 26132,\n",
       " 1559,\n",
       " 9751,\n",
       " 34333,\n",
       " 9759,\n",
       " 9768,\n",
       " 42536,\n",
       " 9771,\n",
       " 1580,\n",
       " 1582,\n",
       " 9775,\n",
       " 1584,\n",
       " 9777,\n",
       " 17971,\n",
       " 75319,\n",
       " 1591,\n",
       " 26168,\n",
       " 1599,\n",
       " 17983,\n",
       " 1602,\n",
       " 9798,\n",
       " 42567,\n",
       " 83528,\n",
       " 9800,\n",
       " 1610,\n",
       " 1611,\n",
       " 1613,\n",
       " 18000,\n",
       " 1622,\n",
       " 99927,\n",
       " 9818,\n",
       " 18011,\n",
       " 1632,\n",
       " 1637,\n",
       " 34409,\n",
       " 1643,\n",
       " 42604,\n",
       " 1647,\n",
       " 1651,\n",
       " 1654,\n",
       " 1658,\n",
       " 18051,\n",
       " 9860,\n",
       " 1669,\n",
       " 9861,\n",
       " 1671,\n",
       " 1679,\n",
       " 1687,\n",
       " 18071,\n",
       " 50849,\n",
       " 1697,\n",
       " 42660,\n",
       " 59049,\n",
       " 34474,\n",
       " 42671,\n",
       " 9904,\n",
       " 75445,\n",
       " 9909,\n",
       " 1718,\n",
       " 1719,\n",
       " 1721,\n",
       " 1722,\n",
       " 1723,\n",
       " 1724,\n",
       " 9915,\n",
       " 26302,\n",
       " 1727,\n",
       " 1728,\n",
       " 9919,\n",
       " 9928,\n",
       " 1741,\n",
       " 1742,\n",
       " 26319,\n",
       " 9933,\n",
       " 9934,\n",
       " 26322,\n",
       " 1748,\n",
       " 1754,\n",
       " 9947,\n",
       " 9950,\n",
       " 59107,\n",
       " 1766,\n",
       " 1767,\n",
       " 1768,\n",
       " 9971,\n",
       " 9972,\n",
       " 9974,\n",
       " 1784,\n",
       " 18168,\n",
       " 26364,\n",
       " 1788,\n",
       " 1790,\n",
       " 1794,\n",
       " 26370,\n",
       " 67330,\n",
       " 9989,\n",
       " 1804,\n",
       " 18190,\n",
       " 1809,\n",
       " 42772,\n",
       " 1812,\n",
       " 1814,\n",
       " 18198,\n",
       " 10006,\n",
       " 1817,\n",
       " 1820,\n",
       " 1821,\n",
       " 10018,\n",
       " 1828,\n",
       " 10020,\n",
       " 1837,\n",
       " 1838,\n",
       " 10032,\n",
       " 1842,\n",
       " 42803,\n",
       " 1844,\n",
       " 10034,\n",
       " 42806,\n",
       " 50999,\n",
       " 18229,\n",
       " 1846,\n",
       " 26425,\n",
       " 1854,\n",
       " 26432,\n",
       " 1865,\n",
       " 18250,\n",
       " 1866,\n",
       " 10057,\n",
       " 18249,\n",
       " 18253,\n",
       " 1871,\n",
       " 1873,\n",
       " 10067,\n",
       " 1875,\n",
       " 1876,\n",
       " 1879,\n",
       " 1884,\n",
       " 1886,\n",
       " 10079,\n",
       " 42848,\n",
       " 10081,\n",
       " 1890,\n",
       " 1891,\n",
       " 10084,\n",
       " 1893,\n",
       " 1895,\n",
       " 10087,\n",
       " 1897,\n",
       " 1899,\n",
       " 42860,\n",
       " 10091,\n",
       " 1901,\n",
       " 1904,\n",
       " 1905,\n",
       " 1906,\n",
       " 10098,\n",
       " 10099,\n",
       " 42868,\n",
       " 1912,\n",
       " 1913,\n",
       " 1914,\n",
       " 10107,\n",
       " 18300,\n",
       " 18301,\n",
       " 1920,\n",
       " 1924,\n",
       " 18310,\n",
       " 1930,\n",
       " 1931,\n",
       " 1932,\n",
       " 10125,\n",
       " 1934,\n",
       " 34703,\n",
       " 18321,\n",
       " 10130,\n",
       " 1939,\n",
       " 26516,\n",
       " 51094,\n",
       " 1946,\n",
       " 1948,\n",
       " 18336,\n",
       " 10145,\n",
       " 1956,\n",
       " 10150,\n",
       " 67494,\n",
       " 34728,\n",
       " 67497,\n",
       " 1959,\n",
       " 10151,\n",
       " 10155,\n",
       " 42923,\n",
       " 10157,\n",
       " 1967,\n",
       " 18350,\n",
       " 26543,\n",
       " 1970,\n",
       " 1974,\n",
       " 10166,\n",
       " 34744,\n",
       " 67512,\n",
       " 18358,\n",
       " 18369,\n",
       " 1987,\n",
       " 26567,\n",
       " 1992,\n",
       " 34759,\n",
       " 10187,\n",
       " 18384,\n",
       " 2001,\n",
       " 10193,\n",
       " 42966,\n",
       " 10204,\n",
       " 2018,\n",
       " 10211,\n",
       " 2020,\n",
       " 2021,\n",
       " 2026,\n",
       " 2027,\n",
       " 10222,\n",
       " 26606,\n",
       " 34800,\n",
       " 18418,\n",
       " 34802,\n",
       " 2035,\n",
       " 2040,\n",
       " 43000,\n",
       " 18431,\n",
       " 10239,\n",
       " 51201,\n",
       " 2057,\n",
       " 2061,\n",
       " 2062,\n",
       " 10254,\n",
       " 2064,\n",
       " 2066,\n",
       " 10259,\n",
       " 10260,\n",
       " 2069,\n",
       " 2071,\n",
       " 10263,\n",
       " 18459,\n",
       " 59420,\n",
       " 10268,\n",
       " 2079,\n",
       " 10276,\n",
       " 43045,\n",
       " 26662,\n",
       " 18477,\n",
       " 34866,\n",
       " 10290,\n",
       " 34872,\n",
       " 10296,\n",
       " 51258,\n",
       " 18491,\n",
       " 34876,\n",
       " 59453,\n",
       " 10300,\n",
       " 2109,\n",
       " 10302,\n",
       " 34881,\n",
       " 10307,\n",
       " 18505,\n",
       " 59467,\n",
       " 18509,\n",
       " 2126,\n",
       " 10320,\n",
       " 18513,\n",
       " 10326,\n",
       " 10333,\n",
       " 10334,\n",
       " 10335,\n",
       " 2146,\n",
       " 2147,\n",
       " 34915,\n",
       " 10338,\n",
       " 2149,\n",
       " 2152,\n",
       " 34920,\n",
       " 10346,\n",
       " 26734,\n",
       " 59505,\n",
       " 2165,\n",
       " 26741,\n",
       " 18552,\n",
       " 43129,\n",
       " 18553,\n",
       " 2170,\n",
       " 10362,\n",
       " 18557,\n",
       " 2175,\n",
       " 10368,\n",
       " 10373,\n",
       " 18567,\n",
       " 10376,\n",
       " 10379,\n",
       " 34955,\n",
       " 10382,\n",
       " 18576,\n",
       " 2198,\n",
       " 10390,\n",
       " 26775,\n",
       " 18587,\n",
       " 2205,\n",
       " 18590,\n",
       " 2207,\n",
       " 10400,\n",
       " 18592,\n",
       " 34976,\n",
       " 100515,\n",
       " 34979,\n",
       " 2214,\n",
       " 2216,\n",
       " 10408,\n",
       " 2218,\n",
       " 10409,\n",
       " 2221,\n",
       " 26797,\n",
       " 34993,\n",
       " 2226,\n",
       " 10418,\n",
       " 2229,\n",
       " 10422,\n",
       " 2238,\n",
       " 2239,\n",
       " 2241,\n",
       " 18629,\n",
       " 10441,\n",
       " 10442,\n",
       " 10444,\n",
       " 2253,\n",
       " 10446,\n",
       " 2255,\n",
       " 2257,\n",
       " 2258,\n",
       " 10451,\n",
       " 35030,\n",
       " 2263,\n",
       " 2264,\n",
       " 18648,\n",
       " 2268,\n",
       " 18655,\n",
       " 18660,\n",
       " 26852,\n",
       " 10469,\n",
       " 10473,\n",
       " 10474,\n",
       " 26858,\n",
       " 10476,\n",
       " 2285,\n",
       " 2287,\n",
       " 2288,\n",
       " 2289,\n",
       " 10481,\n",
       " 10483,\n",
       " 2295,\n",
       " 10488,\n",
       " 10490,\n",
       " 10494,\n",
       " 26881,\n",
       " 2308,\n",
       " 18694,\n",
       " 10503,\n",
       " 2312,\n",
       " 10507,\n",
       " 2317,\n",
       " 10510,\n",
       " 10511,\n",
       " 26896,\n",
       " 2321,\n",
       " 43278,\n",
       " 18710,\n",
       " 2327,\n",
       " 59672,\n",
       " 18712,\n",
       " 10523,\n",
       " 2334,\n",
       " 10527,\n",
       " 2338,\n",
       " 10530,\n",
       " 2341,\n",
       " 2342,\n",
       " 2343,\n",
       " 18726,\n",
       " 18728,\n",
       " 18729,\n",
       " 18731,\n",
       " 18733,\n",
       " 10541,\n",
       " 2355,\n",
       " 2357,\n",
       " 2358,\n",
       " 2359,\n",
       " 2360,\n",
       " 2361,\n",
       " 2362,\n",
       " 2363,\n",
       " 2364,\n",
       " 10549,\n",
       " 10550,\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19fa3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reviews2 = filtered_reviews[~filtered_reviews['User ID'].isin(outlier_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "721e9840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3130</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>3176</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>2472</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>2203</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>928</td>\n",
       "      <td>0</td>\n",
       "      <td>1778</td>\n",
       "      <td>A solid 4 stars for this greek food spot.  If ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358950</th>\n",
       "      <td>14671</td>\n",
       "      <td>349</td>\n",
       "      <td>3398</td>\n",
       "      <td>Made a reservation for an early dinner Saturda...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358952</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>3396</td>\n",
       "      <td>I'm very spoiled with Pizza. Really, I have tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358953</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>3390</td>\n",
       "      <td>Can't say enough good things about this place....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358954</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>3389</td>\n",
       "      <td>Had a great dinner here- fantastic pizza, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358955</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Great foods and great drinks, they have even p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229560 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Product ID  Date  \\\n",
       "1           924           0  3130   \n",
       "2           925           0  3176   \n",
       "3           926           0  2472   \n",
       "4           927           0  2203   \n",
       "5           928           0  1778   \n",
       "...         ...         ...   ...   \n",
       "358950    14671         349  3398   \n",
       "358952   161146         349  3396   \n",
       "358953   116424         349  3390   \n",
       "358954   161147         349  3389   \n",
       "358955    97930         349  3384   \n",
       "\n",
       "                                                   Review  Rating  Label  \n",
       "1       This little place in Soho is wonderful. I had ...       3     -1  \n",
       "2       ordered lunch for 15 from Snack last Friday.  ...       4     -1  \n",
       "3       This is a beautiful quaint little restaurant o...       4     -1  \n",
       "4       Snack is great place for a  casual sit down lu...       4     -1  \n",
       "5       A solid 4 stars for this greek food spot.  If ...       4     -1  \n",
       "...                                                   ...     ...    ...  \n",
       "358950  Made a reservation for an early dinner Saturda...       3      1  \n",
       "358952  I'm very spoiled with Pizza. Really, I have tr...       2      1  \n",
       "358953  Can't say enough good things about this place....       5      1  \n",
       "358954  Had a great dinner here- fantastic pizza, the ...       2      1  \n",
       "358955  Great foods and great drinks, they have even p...       5      1  \n",
       "\n",
       "[229560 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdfdabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalRev = filtered_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a02b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3130</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>3176</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>2472</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>2203</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358952</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>3396</td>\n",
       "      <td>I'm very spoiled with Pizza. Really, I have tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358953</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>3390</td>\n",
       "      <td>Can't say enough good things about this place....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358954</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>3389</td>\n",
       "      <td>Had a great dinner here- fantastic pizza, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358955</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Great foods and great drinks, they have even p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358956</th>\n",
       "      <td>5260</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Pizza Loves Emily and I love Emily's pizza. Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294948 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Product ID  Date  \\\n",
       "0           923           0  3701   \n",
       "1           924           0  3130   \n",
       "2           925           0  3176   \n",
       "3           926           0  2472   \n",
       "4           927           0  2203   \n",
       "...         ...         ...   ...   \n",
       "358952   161146         349  3396   \n",
       "358953   116424         349  3390   \n",
       "358954   161147         349  3389   \n",
       "358955    97930         349  3384   \n",
       "358956     5260         349  3384   \n",
       "\n",
       "                                                   Review  Rating  Label  \n",
       "0       The food at snack is a selection of popular Gr...       3     -1  \n",
       "1       This little place in Soho is wonderful. I had ...       3     -1  \n",
       "2       ordered lunch for 15 from Snack last Friday.  ...       4     -1  \n",
       "3       This is a beautiful quaint little restaurant o...       4     -1  \n",
       "4       Snack is great place for a  casual sit down lu...       4     -1  \n",
       "...                                                   ...     ...    ...  \n",
       "358952  I'm very spoiled with Pizza. Really, I have tr...       2      1  \n",
       "358953  Can't say enough good things about this place....       5      1  \n",
       "358954  Had a great dinner here- fantastic pizza, the ...       2      1  \n",
       "358955  Great foods and great drinks, they have even p...       5      1  \n",
       "358956  Pizza Loves Emily and I love Emily's pizza. Th...       5      1  \n",
       "\n",
       "[294948 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalRev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59950774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TRSM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TRSM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\TRSM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\TRSM\\AppData\\Roaming\\nltk_data...\n",
      "C:\\Users\\TRSM\\AppData\\Local\\Temp\\ipykernel_6088\\2562982414.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FinalRev[['Tokens', 'Punctuation']] = FinalRev['Review'].apply(preprocess_text).apply(pd.Series)\n",
      "C:\\Users\\TRSM\\AppData\\Local\\Temp\\ipykernel_6088\\2562982414.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FinalRev[['Tokens', 'Punctuation']] = FinalRev['Review'].apply(preprocess_text).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words and numbers\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Extract punctuation marks as new feature\n",
    "    punctuation = [token for token in tokens if not token.isalnum()]\n",
    "\n",
    "    # Remove punctuation tokens from the original tokens\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "\n",
    "    # Join the tokens and punctuation back into separate strings\n",
    "    tokens_str = ' '.join(tokens)\n",
    "    punctuation_str = ' '.join(punctuation)\n",
    "\n",
    "    return tokens_str, punctuation_str\n",
    "\n",
    "\n",
    "FinalRev[['Tokens', 'Punctuation']] = FinalRev['Review'].apply(preprocess_text).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3827c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>food snack selection popular greek dish appeti...</td>\n",
       "      <td>. . . 4-5 's .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3130</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>little place soho wonderful lamb sandwich glas...</td>\n",
       "      <td>. . , , . , , n't world-class .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>3176</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>ordered lunch snack last friday time nothing m...</td>\n",
       "      <td>. , . , .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>2472</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>beautiful quaint little restaurant pretty stre...</td>\n",
       "      <td>. 're , . , . 'm . - , - . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>2203</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>snack great place casual sit especially cold w...</td>\n",
       "      <td>lunch- . food- . . ... . . n't , ... `` '' .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358952</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>3396</td>\n",
       "      <td>I'm very spoiled with Pizza. Really, I have tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>spoiled pizza really tried lucali di fara john...</td>\n",
       "      <td>'m . , 's , 's , 's , . , 'm . 's , . . . ! , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358953</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>3390</td>\n",
       "      <td>Can't say enough good things about this place....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ca say enough good thing place stopped last ni...</td>\n",
       "      <td>n't . , pre-dinner . , ; , , . . , , , . , .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358954</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>3389</td>\n",
       "      <td>Had a great dinner here- fantastic pizza, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>great dinner fantastic pizza pizza dessert bit...</td>\n",
       "      <td>here- , s'more . . , .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358955</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Great foods and great drinks, they have even p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>great food great drink even pairing wine pizza...</td>\n",
       "      <td>, ! ! . , , , : )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358956</th>\n",
       "      <td>5260</td>\n",
       "      <td>349</td>\n",
       "      <td>3384</td>\n",
       "      <td>Pizza Loves Emily and I love Emily's pizza. Th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>pizza love emily love emily pizza emily great ...</td>\n",
       "      <td>'s . , . , , . 's , . , , , - . , n't . : - ( ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294948 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Product ID  Date  \\\n",
       "0           923           0  3701   \n",
       "1           924           0  3130   \n",
       "2           925           0  3176   \n",
       "3           926           0  2472   \n",
       "4           927           0  2203   \n",
       "...         ...         ...   ...   \n",
       "358952   161146         349  3396   \n",
       "358953   116424         349  3390   \n",
       "358954   161147         349  3389   \n",
       "358955    97930         349  3384   \n",
       "358956     5260         349  3384   \n",
       "\n",
       "                                                   Review  Rating  Label  \\\n",
       "0       The food at snack is a selection of popular Gr...       3     -1   \n",
       "1       This little place in Soho is wonderful. I had ...       3     -1   \n",
       "2       ordered lunch for 15 from Snack last Friday.  ...       4     -1   \n",
       "3       This is a beautiful quaint little restaurant o...       4     -1   \n",
       "4       Snack is great place for a  casual sit down lu...       4     -1   \n",
       "...                                                   ...     ...    ...   \n",
       "358952  I'm very spoiled with Pizza. Really, I have tr...       2      1   \n",
       "358953  Can't say enough good things about this place....       5      1   \n",
       "358954  Had a great dinner here- fantastic pizza, the ...       2      1   \n",
       "358955  Great foods and great drinks, they have even p...       5      1   \n",
       "358956  Pizza Loves Emily and I love Emily's pizza. Th...       5      1   \n",
       "\n",
       "                                                   Tokens  \\\n",
       "0       food snack selection popular greek dish appeti...   \n",
       "1       little place soho wonderful lamb sandwich glas...   \n",
       "2       ordered lunch snack last friday time nothing m...   \n",
       "3       beautiful quaint little restaurant pretty stre...   \n",
       "4       snack great place casual sit especially cold w...   \n",
       "...                                                   ...   \n",
       "358952  spoiled pizza really tried lucali di fara john...   \n",
       "358953  ca say enough good thing place stopped last ni...   \n",
       "358954  great dinner fantastic pizza pizza dessert bit...   \n",
       "358955  great food great drink even pairing wine pizza...   \n",
       "358956  pizza love emily love emily pizza emily great ...   \n",
       "\n",
       "                                              Punctuation  \n",
       "0                                          . . . 4-5 's .  \n",
       "1                         . . , , . , , n't world-class .  \n",
       "2                                               . , . , .  \n",
       "3                          . 're , . , . 'm . - , - . . .  \n",
       "4            lunch- . food- . . ... . . n't , ... `` '' .  \n",
       "...                                                   ...  \n",
       "358952  'm . , 's , 's , 's , . , 'm . 's , . . . ! , ...  \n",
       "358953       n't . , pre-dinner . , ; , , . . , , , . , .  \n",
       "358954                             here- , s'more . . , .  \n",
       "358955                                  , ! ! . , , , : )  \n",
       "358956  's . , . , , . 's , . , , , - . , n't . : - ( ...  \n",
       "\n",
       "[294948 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalRev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f731f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"FinalRev.xlsx\" download>Download Excel file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Convert DataFrame to Excel and display as link\n",
    "filename = 'FinalRev.xlsx'\n",
    "FinalRev.to_excel(filename, index=False, sheet_name='Sheet1')\n",
    "HTML(f'<a href=\"{filename}\" download>Download Excel file</a>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9c9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Nowrev = pd.read_csv('FinalRev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7788e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.20.3\n",
      "  Using cached numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 KB\u001b[0m \u001b[31m741.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.2 pandas-2.0.0 pytz-2023.3 tzdata-2023.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/home/seankhatiri/sean2/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca4d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID           0\n",
      "Product ID        0\n",
      "Date              0\n",
      "Review            4\n",
      "Rating            0\n",
      "Label             0\n",
      "Tokens           64\n",
      "Punctuation    1671\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Nowrev.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c7c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nowrev.dropna(subset=['Tokens'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b91a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.9/site-packages (from scikit-learn) (1.24.2)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/home/seankhatiri/sean2/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7c4a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into training and testing sets\n",
    "X = Nowrev[['Date', 'Tokens', 'Rating']]\n",
    "y = Nowrev['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5d3031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (58.1.0)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.1.tar.gz (137 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from torchvision) (1.24.2)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting requests\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m180.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.3.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using legacy 'setup.py install' for lit, since package 'wheel' is not installed.\n",
      "Installing collected packages: tokenizers, mpmath, lit, cmake, wheel, urllib3, tqdm, sympy, regex, pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, filelock, charset-normalizer, certifi, requests, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, transformers, triton, torch, torchvision\n",
      "  Running setup.py install for lit ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed certifi-2022.12.7 charset-normalizer-3.1.0 cmake-3.26.3 filelock-3.11.0 huggingface-hub-0.13.4 lit-16.0.1 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pillow-9.5.0 regex-2023.3.23 requests-2.28.2 sympy-1.11.1 tokenizers-0.13.3 torch-2.0.0 torchvision-0.15.1 tqdm-4.65.0 transformers-4.27.4 triton-2.0.0 urllib3-1.26.15 wheel-0.40.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/home/seankhatiri/sean2/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#from here is BERT however I couldn't run it finally\n",
    "#pip install torch torchvision transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb59d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "#from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "#from transformers import BertForSequenceClassification, BertTokenizer, BertConfig, AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9830ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#reviews = Nowrev['Tokens'].values\n",
    "#labels = Nowrev['Label'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e683548d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = (labels + 1)//2\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d9fb01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FakeReviewDataset(Dataset):\n",
    "#     def __init__(self, reviews, labels, tokenizer, max_length):\n",
    "#         self.reviews = reviews\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.reviews)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         review = self.reviews[idx]\n",
    "#         label = self.labels[idx]\n",
    "\n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#             review,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_token_type_ids=False,\n",
    "#             padding='max_length',\n",
    "#             return_attention_mask=True,\n",
    "#             return_tensors='pt',\n",
    "#             truncation=True\n",
    "#         )\n",
    "\n",
    "#         return {\n",
    "#             'review_text': review,\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'label': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# max_length = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cb50f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_reviews, val_reviews, train_labels, val_labels = train_test_split(reviews, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_dataset = FakeReviewDataset(train_reviews, train_labels, tokenizer, max_length)\n",
    "# val_dataset = FakeReviewDataset(val_reviews, val_labels, tokenizer, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09ce5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 8\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "# val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ddc054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'classifier.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'classifier.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0348b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.0 MB\n",
      "Free memory: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# def get_gpu_memory_status(device=None):\n",
    "#     if device is None:\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "#     if device.type == 'cuda':\n",
    "#         torch.cuda.empty_cache()\n",
    "#         allocated_memory = torch.cuda.memory_allocated(device)\n",
    "#         free_memory = torch.cuda.memory_reserved(device) - allocated_memory\n",
    "#         return allocated_memory, free_memory\n",
    "#     else:\n",
    "#         return None, None\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "#     allocated_memory, free_memory = get_gpu_memory_status(device)\n",
    "#     print(f\"Allocated memory: {allocated_memory / 1024 ** 2} MB\")\n",
    "#     print(f\"Free memory: {free_memory / 1024 ** 2} MB\")\n",
    "# else:\n",
    "#     print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad3947ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "# epochs = 3\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "133565c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, dataloader, optimizer, scheduler, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "\n",
    "#     for batch in dataloader:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f762d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (4.65.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1 is available.\n",
      "You should consider upgrading via the '/home/seankhatiri/sean2/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765ed19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 29489/29489 [14:12<00:00, 34.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# import multiprocessing\n",
    "\n",
    "# def train_model(model, dataloader, optimizer, scheduler, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "\n",
    "   \n",
    "#     pool = multiprocessing.Pool()\n",
    "\n",
    "    \n",
    "#     progress_bar = tqdm(dataloader, desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     for batch in progress_bar:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         result = pool.apply_async(model, (input_ids, attention_mask, labels))\n",
    "#         results.append(result)\n",
    "\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n",
    "#     for result in tqdm(results, desc=\"Calculating loss\", position=1, leave=True):\n",
    "#         outputs = result.get()\n",
    "#         loss = outputs[0]\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = total_loss / len(dataloader)\n",
    "\n",
    "#     return avg_train_loss\n",
    "\n",
    "# # Evaluation loop\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "\n",
    "#     # Adding a progress bar\n",
    "#     progress_bar = tqdm(dataloader, desc=\"Evaluating\", position=0, leave=True)\n",
    "\n",
    "#     for batch in progress_bar:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#             loss = outputs[0]\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#     avg_val_loss = total_loss / len(dataloader)\n",
    "\n",
    "#     return avg_val_loss\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     train_loss = train_model(model, train_dataloader, optimizer, scheduler, 'cpu')\n",
    "#     val_loss = evaluate_model(model, val_dataloader, 'cpu')\n",
    "\n",
    "#     print(f\"\\nEpoch: {epoch + 1}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f}\")\n",
    "#     print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "#     val_predictions, val_true_labels = get_predictions(model, val_dataloader, 'cuda')\n",
    "#     val_predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "#     print(\"\\nPerformance metrics on validation dataset:\")\n",
    "#     print(\"Accuracy:\", accuracy_score(val_true_labels, val_predicted_labels))\n",
    "#     print(\"\\nClassification report:\")\n",
    "#     print(classification_report(val_true_labels, val_predicted_labels))\n",
    "\n",
    "# val_predictions, val_true_labels = get_predictions(model, val_dataloader, 'cuda')\n",
    "# val_predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# print(\"\\nPerformance metrics on validation dataset:\")\n",
    "# print(\"Accuracy:\", accuracy_score(val_true_labels, val_predicted_labels))\n",
    "# print(\"\\nClassification report:\")\n",
    "# print(classification_report(val_true_labels, val_predicted_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72a7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_cv = cv.fit_transform(X_train['Tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de300ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV accuracy: 0.8945643848020517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seankhatiri/sean2/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy: 0.8940603964257253\n",
      "Precision: 0.9006877437897762\n",
      "Recall: 0.9916556790355999\n",
      "F1 Score: 0.9439852252963009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# n_jobs=-1 to use all avaliable CPUs\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "# Perform 10 fold cross validation on training data\n",
    "cv_scores = cross_val_score(lr, X_train_cv, y_train, cv=10, n_jobs=-1)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "# Fitting the model\n",
    "lr.fit(X_train_cv, y_train)\n",
    "\n",
    "# Transform testing data using CountVectorizer\n",
    "X_test_cv = cv.transform(X_test[\"Tokens\"])\n",
    "\n",
    "y_pred = lr.predict(X_test_cv)\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print('LogisticRegression Accuracy:', accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c77ea7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV accuracy: 0.898036090850131\n",
      "Multinomial Naive Bayes Accuracy: 0.9000288247961069\n",
      "Precision: 0.9001797646101143\n",
      "Recall: 0.9998116406102844\n",
      "F1 Score: 0.9473834511315771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "cv_scores = cross_val_score(nb, X_train_cv, y_train, cv=10)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "nb.fit(X_train_cv, y_train)\n",
    "y_pred_nb = nb.predict(X_test_cv)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print('Multinomial Naive Bayes Accuracy:', accuracy_nb)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_nb)\n",
    "recall = recall_score(y_test, y_pred_nb)\n",
    "f1 = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a96e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV accuracy: 0.8569690672625404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRSM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy: 0.8555708157417298\n",
      "Precision: 0.9015784921435779\n",
      "Recall: 0.9424373705029195\n",
      "F1 Score: 0.9215552649512827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "cv_scores = cross_val_score(svm, X_train_cv, y_train, cv=10)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "svm.fit(X_train_cv, y_train)\n",
    "y_pred_svm = svm.predict(X_test_cv)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print('Support Vector Machine Accuracy:', accuracy_svm)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_svm)\n",
    "recall = recall_score(y_test, y_pred_svm)\n",
    "f1 = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_train_cv, y_train, cv=10, n_jobs=-1)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "rf.fit(X_train_cv, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_cv)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print('Random Forest Accuracy:', accuracy_rf)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "recall = recall_score(y_test, y_pred_rf)\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_cv, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(gb, X_train_cv, y_train, cv=10)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "y_pred_gb = gb.predict(X_test_cv)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print('Gradient Boosting Accuracy:', accuracy_gb)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_gb)\n",
    "recall = recall_score(y_test, y_pred_gb)\n",
    "f1 = f1_score(y_test, y_pred_gb)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e0eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV accuracy: 0.896710011236013\n",
      "XGBoost Accuracy: 0.8991331242376721\n",
      "Precision: 0.8993094133281049\n",
      "Recall: 0.9997820295471058\n",
      "F1 Score: 0.946887938251924\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "y_train_mapped = (y_train + 1) // 2\n",
    "y_test_mapped = (y_test + 1) // 2\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "cv_scores = cross_val_score(xgb_clf, X_train_cv, y_train_mapped, cv=10)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "xgb_clf.fit(X_train_cv, y_train_mapped)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_test_cv)\n",
    "accuracy_xgb = accuracy_score(y_test_mapped, y_pred_xgb)\n",
    "print('XGBoost Accuracy:', accuracy_xgb)\n",
    "\n",
    "precision = precision_score(y_test_mapped, y_pred_xgb)\n",
    "recall = recall_score(y_test_mapped, y_pred_xgb)\n",
    "f1 = f1_score(y_test_mapped, y_pred_xgb)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe02190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\trsm\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\trsm\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\trsm\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b95d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "cv_scores = cross_val_score(dt, X_train_cv, y_train, cv=10)\n",
    "\n",
    "print('Mean CV accuracy:', cv_scores.mean())\n",
    "\n",
    "dt.fit(X_train_cv, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_cv)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print('Decision Tree Accuracy:', accuracy_dt)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_dt)\n",
    "recall = recall_score(y_test, y_pred_dt)\n",
    "f1 = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e302e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "models = joblib.load('models.pkl')\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', models['lr']),\n",
    "    ('nb', models['nb']),\n",
    "    ('svm', models['svm'])],\n",
    "    voting='hard')\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_test_cv = cv.fit_transform(X_test)\n",
    "\n",
    "y_pred_ensemble = ensemble.predict(X_test_cv)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "precision_ensemble = precision_score(y_test, y_pred_ensemble)\n",
    "recall_ensemble = recall_score(y_test, y_pred_ensemble)\n",
    "f1_ensemble = f1_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print('Ensemble Accuracy:', accuracy_ensemble)\n",
    "print('Precision:', precision_ensemble)\n",
    "print('Recall:', recall_ensemble)\n",
    "print('F1 Score:', f1_ensemble)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
